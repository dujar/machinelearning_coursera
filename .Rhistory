accuracy <- postResample(tree_out, Testing$classe)
#show table
tab <- tree_ct
kable(tab[2],caption="confusion table of the tree model")
rm(tree_out)
kable(tab$overall)
#rf - random forest
rf_ <- train(classe ~ ., data=Training3, method="rf", verbose=FALSE, trControl=trainControl(method ="cv",5), ntree = 250)
#predict
rf.out <- predict(rf_,newdata=Testing)
#contigency table
rf.ct <- confusionMatrix(rf.out,Testing$classe)
#show table
tab <- rf.ct
kable(tab[2],caption="confusion table of the Random Forest model")
rm(rf_out)
rm(rf_ct)
kable(tab$overall)
#shrinking the amount of variables of the prediction data to be the same as the training data.
Testing_forprediction <- Testing_forprediction[,.SD,.SDcols=names(Training3)[-length(Training3)]]
#spotting the variables with different data types
#notequal <- Testing[,lapply(.SD,class)]!=Testing_forprediction[,lapply(.SD,class)]
#Testing_forprediction[,as.vector(notequal), with=FALSE]
#for (col in names(one)) set(one, j = col, value= class(two[[col]]))
#two[,lapply(.SD,class)]
Model.tree <- predict(tree_,newdata=Testing_forprediction)
Model.rf <- predict(rf_,newdata=Testing_forprediction)
result_predictions = data.frame(Model.rf)
kable(data.frame(result_predictions), caption=" results for the final quiz")
write.table(result_predictions, "results.csv")
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
library(caret)
library(ggplot2)
library(data.table)
library(cowplot)
library(knitr)
library(rpart)
library(rpart.plot)
library(pander)
library(kableExtra)
options(knitr.tableformat="html")
Testing_forprediction <- data.table(read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!","")))
Data <- data.table(read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!","")))
set.seed(123)
#Partitioning the training set into 2
inTrain <- createDataPartition(Data$classe,p=0.70,list=FALSE)
Training <- Data[inTrain,]
Testing <- Data[-inTrain,]
cols <- nearZeroVar(Training)
nearZeroVar(Training, saveMetrics=T)
length(cols)# number of variables dropped
head(cols,10)
dropped1 <- Training[,.SD,.SDcols=cols]
Training1 <- Training[,.SD,.SDcols=-cols]
library(reshape2)
numeric_cols <- Training1[,sapply(.SD,is.numeric)]
cormat <- Training1[,cor(.SD,use="pairwise.complete.obs"),.SDcols=numeric_cols]
##helper function used from sthda website
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}
# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
#code for ggheatmap has been hidden because it takes too much space for this assignment. Kindly check github for it.
# Print the heatmap
ggheatmap
melted_cormat <- data.table(melted_cormat)
ggplot(data=melted_cormat[value!=1,],aes(value)) + geom_histogram(bins=100)
above_0.9 <- melted_cormat[value!=1,][value>0.9|value< -0.9,]
above_0.9 <- above_0.9[order(-abs(value),Var1), ]
kable(head(above_0.9,5))
name_todrop2<- above_0.9[,unique(Var1)]
Training2 <- Training1[,.SD,.SDcols=-as.character(name_todrop2)]
dim(Training2)
Training2[,levels(classe)]
descr <- Training[,.N,by=c("classe","user_name")]
kable(dcast(descr,user_name ~ classe), caption="amount of observations per user by class")
Training2 <- Training2[,.SD,.SDcols= -c("raw_timestamp_part_1","raw_timestamp_part_2")]
missing <-Training2[,lapply(.SD,is.na)][,lapply(.SD,sum)][,lapply(.SD,function(x){if(x>0) x})]
length(missing)
missing[,1]/dim(Training2)[1]
missing
M<-Training2[,.SD,.SDcols=c("classe",names(missing))]
kable(M[,lapply(.SD,is.na),by=classe][,lapply(.SD,sum,na.rm=T),by=classe][,1:2])
Training3 <- Training2[,.SD,.SDcols= -names(missing)]
dim(Training3)
dim(Training3) == dim(na.omit(Training3))
tree_ <- rpart(classe ~ ., data=Training3, method="class")
prp(tree_)
tree_out <- predict(tree_, Testing, type = "class")
tree_ct <- confusionMatrix(Testing$classe, tree_out)
tree_ct
accuracy <- postResample(tree_out, Testing$classe)
#show table
tab <- tree_ct
kable(tab[2],caption="confusion table of the tree model")
rm(tree_out)
kable(tab$overall)
#rf - random forest
rf_ <- train(classe ~ ., data=Training3, method="rf", verbose=FALSE, trControl=trainControl(method ="cv",5), ntree = 250)
#predict
rf.out <- predict(rf_,newdata=Testing)
#contigency table
rf.ct <- confusionMatrix(rf.out,Testing$classe)
#show table
tab <- rf.ct
kable(tab[2],caption="confusion table of the Random Forest model")
rm(rf_out)
rm(rf_ct)
kable(tab$overall)
#shrinking the amount of variables of the prediction data to be the same as the training data.
Testing_forprediction[,.SD,.SDcols=names(Training3)[-length(Training3)]]
#spotting the variables with different data types
#notequal <- Testing[,lapply(.SD,class)]!=Testing_forprediction[,lapply(.SD,class)]
#Testing_forprediction[,as.vector(notequal), with=FALSE]
#for (col in names(one)) set(one, j = col, value= class(two[[col]]))
#two[,lapply(.SD,class)]
Model.tree <- predict(tree_,newdata=Testing_forprediction)
Model.rf <- predict(rf_,newdata=Testing_forprediction)
result_predictions = data.frame(Model.rf)
kable(data.frame(result_predictions), caption=" results for the final quiz")
write.table(result_predictions, "results.csv")
result_predictions = data.frame(Model.tree)
kable(data.frame(result_predictions), caption=" results for the final quiz")
result_predictions
notequal <- Testing[,lapply(.SD,class)]!=Testing_forprediction[,lapply(.SD,class)]
notequal
Testing_forprediction <- data.table(read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!","")))
Model.tree <- predict(tree_,newdata=Testing_forprediction)
Model.rf <- predict(rf_,newdata=Testing_forprediction)
result_predictions = data.frame(Model.tree)
kable(data.frame(result_predictions), caption=" results for the final quiz")
result_predictions
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
library(caret)
library(ggplot2)
library(data.table)
library(cowplot)
library(knitr)
library(rpart)
library(rpart.plot)
library(pander)
library(kableExtra)
options(knitr.tableformat="html")
Testing_forprediction <- data.table(read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!","")))
Data <- data.table(read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!","")))
set.seed(123)
#Partitioning the training set into 2
inTrain <- createDataPartition(Data$classe,p=0.70,list=FALSE)
Training <- Data[inTrain,]
Testing <- Data[-inTrain,]
cols <- nearZeroVar(Training)
nearZeroVar(Training, saveMetrics=T)
length(cols)# number of variables dropped
head(cols,10)
dropped1 <- Training[,.SD,.SDcols=cols]
Training1 <- Training[,.SD,.SDcols=-cols]
library(reshape2)
numeric_cols <- Training1[,sapply(.SD,is.numeric)]
cormat <- Training1[,cor(.SD,use="pairwise.complete.obs"),.SDcols=numeric_cols]
##helper function used from sthda website
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}
# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
#code for ggheatmap has been hidden because it takes too much space for this assignment. Kindly check github for it.
# Print the heatmap
ggheatmap
melted_cormat <- data.table(melted_cormat)
ggplot(data=melted_cormat[value!=1,],aes(value)) + geom_histogram(bins=100)
above_0.9 <- melted_cormat[value!=1,][value>0.9|value< -0.9,]
above_0.9 <- above_0.9[order(-abs(value),Var1), ]
kable(head(above_0.9,5))
name_todrop2<- above_0.9[,unique(Var1)]
Training2 <- Training1[,.SD,.SDcols=-as.character(name_todrop2)]
dim(Training2)
Training2[,levels(classe)]
descr <- Training[,.N,by=c("classe","user_name")]
kable(dcast(descr,user_name ~ classe), caption="amount of observations per user by class")
Training2 <- Training2[,.SD,.SDcols= -c("raw_timestamp_part_1","raw_timestamp_part_2")]
missing <-Training2[,lapply(.SD,is.na)][,lapply(.SD,sum)][,lapply(.SD,function(x){if(x>0) x})]
length(missing)
missing[,1]/dim(Training2)[1]
missing
M<-Training2[,.SD,.SDcols=c("classe",names(missing))]
kable(M[,lapply(.SD,is.na),by=classe][,lapply(.SD,sum,na.rm=T),by=classe][,1:2])
Training3 <- Training2[,.SD,.SDcols= -names(missing)]
dim(Training3)
dim(Training3) == dim(na.omit(Training3))
tree_ <- rpart(classe ~ ., data=Training3, method="class")
prp(tree_)
tree_out <- predict(tree_, Testing, type = "class")
tree_ct <- confusionMatrix(Testing$classe, tree_out)
tree_ct
accuracy <- postResample(tree_out, Testing$classe)
#show table
tab <- tree_ct
kable(tab[2],caption="confusion table of the tree model")
rm(tree_out)
kable(tab$overall)
#rf - random forest
rf_ <- train(classe ~ ., data=Training3, method="rf", verbose=FALSE, trControl=trainControl(method ="cv",5), ntree = 250)
#predict
rf.out <- predict(rf_,newdata=Testing)
#contigency table
rf.ct <- confusionMatrix(rf.out,Testing$classe)
#show table
tab <- rf.ct
kable(tab[2],caption="confusion table of the Random Forest model")
rm(rf_out)
rm(rf_ct)
kable(tab$overall)
#shrinking the amount of variables of the prediction data to be the same as the training data.
#Testing_forprediction[,.SD,.SDcols=names(Training3)[-length(Training3)]]
#spotting the variables with different data types
#notequal <- Testing[,lapply(.SD,class)]!=Testing_forprediction[,lapply(.SD,class)]
#notequal
#Testing_forprediction[,as.vector(notequal), with=FALSE]
#for (col in names(one)) set(one, j = col, value= class(two[[col]]))
#two[,lapply(.SD,class)]
Model.tree <- predict(tree_,newdata=Testing_forprediction)
Model.rf <- predict(rf_,newdata=Testing_forprediction)
result_predictions = data.frame(Model.tree)
kable(data.frame(result_predictions), caption=" results for the final quiz")
result_predictions = data.frame(Model.rf)
kable(data.frame(result_predictions), caption=" results for the final quiz")
write.table(result_predictions, "results.csv")
result_predictions = data.frame(Model.rf)
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
library(caret)
library(ggplot2)
library(data.table)
library(cowplot)
library(knitr)
library(rpart)
library(rpart.plot)
library(pander)
library(kableExtra)
options(knitr.tableformat="html")
Testing_forprediction <- data.table(read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!","")))
Data <- data.table(read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!","")))
set.seed(123)
#Partitioning the training set into 2
inTrain <- createDataPartition(Data$classe,p=0.70,list=FALSE)
Training <- Data[inTrain,]
Testing <- Data[-inTrain,]
cols <- nearZeroVar(Training)
nearZeroVar(Training, saveMetrics=T)
length(cols)# number of variables dropped
head(cols,10)
dropped1 <- Training[,.SD,.SDcols=cols]
Training1 <- Training[,.SD,.SDcols=-cols]
library(reshape2)
numeric_cols <- Training1[,sapply(.SD,is.numeric)]
cormat <- Training1[,cor(.SD,use="pairwise.complete.obs"),.SDcols=numeric_cols]
##helper function used from sthda website
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}
# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
#code for ggheatmap has been hidden because it takes too much space for this assignment. Kindly check github for it.
# Print the heatmap
ggheatmap
melted_cormat <- data.table(melted_cormat)
ggplot(data=melted_cormat[value!=1,],aes(value)) + geom_histogram(bins=100)
above_0.9 <- melted_cormat[value!=1,][value>0.9|value< -0.9,]
above_0.9 <- above_0.9[order(-abs(value),Var1), ]
kable(head(above_0.9,5))
name_todrop2<- above_0.9[,unique(Var1)]
Training2 <- Training1[,.SD,.SDcols=-as.character(name_todrop2)]
dim(Training2)
Training2[,levels(classe)]
descr <- Training[,.N,by=c("classe","user_name")]
kable(dcast(descr,user_name ~ classe), caption="amount of observations per user by class")
Training2 <- Training2[,.SD,.SDcols= -c("raw_timestamp_part_1","raw_timestamp_part_2")]
missing <-Training2[,lapply(.SD,is.na)][,lapply(.SD,sum)][,lapply(.SD,function(x){if(x>0) x})]
length(missing)
missing[,1]/dim(Training2)[1]
missing
M<-Training2[,.SD,.SDcols=c("classe",names(missing))]
kable(M[,lapply(.SD,is.na),by=classe][,lapply(.SD,sum,na.rm=T),by=classe][,1:2])
Training3 <- Training2[,.SD,.SDcols= -names(missing)]
dim(Training3)
dim(Training3) == dim(na.omit(Training3))
tree_ <- rpart(classe ~ ., data=Training3, method="class")
prp(tree_)
tree_out <- predict(tree_, Testing, type = "class")
tree_ct <- confusionMatrix(Testing$classe, tree_out)
tree_ct
accuracy <- postResample(tree_out, Testing$classe)
#show table
tab <- tree_ct
kable(tab[2],caption="confusion table of the tree model")
rm(tree_out)
kable(tab$overall)
#rf - random forest
rf_ <- train(classe ~ ., data=Training3, method="rf", verbose=FALSE, trControl=trainControl(method ="cv",5), ntree = 250)
#predict
rf.out <- predict(rf_,newdata=Testing)
#contigency table
rf.ct <- confusionMatrix(rf.out,Testing$classe)
#show table
tab <- rf.ct
kable(tab[2],caption="confusion table of the Random Forest model")
rm(rf_out)
rm(rf_ct)
kable(tab$overall)
#shrinking the amount of variables of the prediction data to be the same as the training data.
#Testing_forprediction[,.SD,.SDcols=names(Training3)[-length(Training3)]]
#spotting the variables with different data types
#notequal <- Testing[,lapply(.SD,class)]!=Testing_forprediction[,lapply(.SD,class)]
#notequal
#Testing_forprediction[,as.vector(notequal), with=FALSE]
#for (col in names(one)) set(one, j = col, value= class(two[[col]]))
#two[,lapply(.SD,class)]
Model.tree <- predict(tree_,newdata=Testing_forprediction)
Model.rf <- predict(rf_,newdata=Testing_forprediction)
result_predictions = data.frame(Model.tree)
kable(data.frame(result_predictions), caption=" results for the final quiz")
result_predictions = data.frame(Model.rf)
kable(data.frame(result_predictions), caption=" results for the final quiz")
write.table(result_predictions, "results.csv")
result_predictions
View(Training3)
Model.rf
Model.tree
Model.tree <- predict(tree_,Testing_forprediction)
Model.rf <- predict(rf_,Testing_forprediction)
Model.tree
Model.tree
unlink('Desktop/Coursera/machine learning/Machine_learning_assignment/machinelearningassignment_cache', recursive = TRUE)
source('~/.active-rstudio-document')
source('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
pwd()
cwd()
pwd
pwd
getwd()
cws('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
cwd('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
setwd('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
setwd('~/Desktop/Coursera/machine learning/Machine_learning_assignment')
source('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
source('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
source('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
source('~/Desktop/Coursera/machine learning/Machine_learning_assignment/test.R')
result_predictions = data.frame(Model.rf)
result_predictions
NAMES <- names(Training3)
NAMES
removenames <- c("user_name","cvtd_timestamp")
DATA <- Training3[,-removenames]
DATA <- Training3[,.SD,.SDcols=-removenames]
names(DATA)
rf_ <- train(classe ~ ., data=DATA, method="rf", verbose=FALSE, trControl=trainControl(method ="cv",4), ntree = 250)
names(Training)
names(DATA)
rf_ <- train(classe ~ ., data=DATA, method="rf", verbose=FALSE, trControl=trainControl(method ="cv",4), ntree = 250)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
result_predictions
rf_ <- randomForest(classe ~ ., data=DATA, verbose=FALSE, ntree = 20, importance=TRUE)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
result_predictions
result_predictions["A",]
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, verbose=FALSE, ntree = 250, importance=TRUE)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, verbose=FALSE, ntree = 5, importance=TRUE)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, verbose=FALSE, importance=TRUE)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=20, verbose=FALSE, importance=TRUE)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=25, verbose=FALSE, importance=TRUE)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=26, verbose=FALSE, importance=TRUE)
names(Training)
names(DATA)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=4, verbose=FALSE, importance=TRUE)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=3, verbose=FALSE, importance=TRUE)
names(Training)
names(DATA)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=2, verbose=FALSE, importance=TRUE)
names(Training)
names(DATA)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=1, verbose=FALSE, importance=TRUE)
names(Training)
names(DATA)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
removenames <- c("user_name","cvtd_timestamp","X","num_window")
DATA <- Training3[,.SD,.SDcols=-removenames]
names(DATA)
rf_ <- randomForest(classe ~ ., data=DATA, ntree=3, verbose=FALSE, importance=TRUE)
rf.out <- predict(rf_,newdata=Testing)
Model.rf <- predict(rf_,Testing_forprediction)
result_predictions = data.frame(Model.rf)
table(result_predictions)
result_predictions
confusionMatrix(Testing$classe, rf.out)
