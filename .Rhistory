knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
library(caret)
library(ggplot2)
library(data.table)
library(cowplot)
library(knitr)
library(pander)
library(kableExtra)
options(knitr.tableformat="html")
Testing_forprediction <- data.table(read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!","")))
Data <- data.table(read.csv("pml-training.csv",na.strings=c("NA","#DIV/0!","")))
set.seed(123)
#Partitioning the training set into 2
inTrain <- createDataPartition(Data$classe,p=0.75,list=FALSE)
Training <- Data[inTrain,]
Testing <- Data[-inTrain,]
cols <- nearZeroVar(Training)
length(cols)# number of variables dropped
dropped1<- Training[,.SD,.SDcols=cols]
Training1 <- Training[,.SD,.SDcols=-cols]
library(reshape2)
numeric_cols <- Training1[,sapply(.SD,is.numeric)]
cormat <- Training1[,cor(.SD,use="pairwise.complete.obs"),.SDcols=numeric_cols]
##helper function used from sthda website
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}
# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
#code for ggheatmap has been hidden because it takes too much space for this assignment. Kindly check github for it.
# Print the heatmap
ggheatmap
melted_cormat <- data.table(melted_cormat)
ggplot(data=melted_cormat[value!=1,],aes(value)) + geom_histogram(bins=100)
above_0.9 <- melted_cormat[value!=1,][value>0.9|value< -0.9,]
above_0.9 <- above_0.9[order(-abs(value),Var1), ]
kable(head(above_0.9,5))
name_todrop2<- above_0.9[,unique(Var1)]
Training2 <- Training1[,.SD,.SDcols=-as.character(name_todrop2)]
dim(Training2)
Training2[,levels(classe)]
descr <- Training[,.N,by=c("classe","user_name")]
kable(dcast(descr,user_name ~ classe), caption="amount of observations per user by class")
Training2 <- Training2[,.SD,.SDcols= -c("raw_timestamp_part_1","raw_timestamp_part_2")]
missing <-Training2[,lapply(.SD,is.na)][,lapply(.SD,sum)][,lapply(.SD,function(x){if(x>0) x})]
length(missing)
missing[,1]/dim(Training2)[1]
missing
M<-Training2[,.SD,.SDcols=c("classe",names(missing))]
kable(M[,lapply(.SD,is.na),by=classe][,lapply(.SD,sum,na.rm=T),by=classe][,1:2])
Training3 <- Training2[,.SD,.SDcols= -names(missing)]
dim(Training3)
dim(Training3) == dim(na.omit(Training3))
#bagging -  treebag
bag_ <- train(classe ~ ., data=Training3, method="treebag", verbose=FALSE)
